{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "821e2818-cc83-4709-9a89-fbd8a8f446e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# settings.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#dotenv_path = join(dirname(__file__), '../config/dev.env')\n",
    "load_dotenv(\"../config/dev.env\")\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory \n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a57a1deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==2.0.1\n",
      "pip==23.2.1\n",
      "langchain==0.0.264\n",
      "openai==0.27.8\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import openai\n",
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64589ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.2\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd76cf",
   "metadata": {},
   "source": [
    "## BBDT Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b34b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/modules/memory/\n",
    "\n",
    "user_profile = str({'name': 'Jane', 'height': 70, 'weight': 200})\n",
    "weight = 200\n",
    "height = 70\n",
    "gender = 'female'\n",
    "line1 = f\"\"\" You are an online Nutrition Coach.Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.  \\nYou are not a doctor and you do not give medical advice.\"\"\"\n",
    "line2 = f\"\"\" Here is some general info about the client height: {height}, weight: {weight}, gender: {gender} \"\"\"\n",
    "line3 = f\"\"\" If you don't know the answer to a question, you can say \"I don't know\" or \"I'm not sure\" \"\"\"\n",
    "template = f\"\"\"{line1} \\n{line2} \\n{line3}\"\"\"\n",
    "\n",
    "llm = OpenAI(temperature=0.4)\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(input_variables=[\"height\", \"weight\", \"gender\"], template=template),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8695830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==2.0.1\n",
      "pip==23.2.1\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875ea818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem:  You are an online Nutrition Coach.Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.  \n",
      "You are not a doctor and you do not give medical advice. \n",
      " Here is some general info about the client height: 70, weight: 200, gender: female  \n",
      " If you don't know the answer to a question, you can say \"I don't know\" or \"I'm not sure\" \n",
      "Human: What is the best diet for me?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the best diet for me?',\n",
       " 'chat_history': [HumanMessage(content='What is the best diet for me?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"\\n\\nSystem: It's hard to say what the best diet for you is without more information. Everyone's nutritional needs are different and depend on a variety of factors such as activity level, medical history, and lifestyle. I recommend speaking with a registered dietitian or nutritionist to develop a personalized plan that fits your needs.\", additional_kwargs={}, example=False)],\n",
       " 'text': \"\\n\\nSystem: It's hard to say what the best diet for you is without more information. Everyone's nutritional needs are different and depend on a variety of factors such as activity level, medical history, and lifestyle. I recommend speaking with a registered dietitian or nutritionist to develop a personalized plan that fits your needs.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"What is the best diet for me?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b99ce164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem:  You are an online Nutrition Coach.Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.  \n",
      "You are not a doctor and you do not give medical advice. \n",
      " Here is some general info about the client height: 70, weight: 200, gender: female  \n",
      " If you don't know the answer to a question, you can say \"I don't know\" or \"I'm not sure\" \n",
      "Human: What is the best diet for me?\n",
      "AI: \n",
      "\n",
      "System: It's hard to say what the best diet for you is without more information. Everyone's nutritional needs are different and depend on a variety of factors such as activity level, medical history, and lifestyle. I recommend speaking with a registered dietitian or nutritionist to develop a personalized plan that fits your needs.\n",
      "Human: am i overweight?\n",
      "AI:  \n",
      "AI:\n",
      "\n",
      "System: Based on your height and weight, it appears that you are slightly overweight. However, it's important to remember that body weight is not the only indicator of health. Your body composition and overall health are more important than your weight.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: am i overweight?\n",
      "AI: \n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: Based on your height and weight, it appears that you are slightly overweight. However, it's important to remember that body weight is not the only indicator of health. Your body composition and overall health are more important than your weight.\n",
      "Human: am i overweight?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "AI:\n",
      "\n",
      "System: Based on your height and weight, it appears that you are slightly overweight. However, it's important to remember that body weight is not the only indicator of health. Your body composition and overall health are more important than your weight.\n"
     ]
    }
   ],
   "source": [
    "rsp = conversation({\"question\": \"am i overweight?\"})\n",
    "print(rsp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bd2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem:  You are an online Nutrition Coach.Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.  \n",
      "You are not a doctor and you do not give medical advice. \n",
      " Here is some general info about the client height: 70, weight: 200, gender: female  \n",
      " If you don't know the answer to a question, you can say \"I don't know\" or \"I'm not sure\" \n",
      "Human: What is the best diet for me?\n",
      "AI: \n",
      "\n",
      "System: It's hard to say what the best diet for you is without more information. Everyone's nutritional needs are different and depend on a variety of factors such as activity level, medical history, and lifestyle. I recommend speaking with a registered dietitian or nutritionist to develop a personalized plan that fits your needs.\n",
      "Human: am i overweight?\n",
      "AI:  \n",
      "AI:\n",
      "\n",
      "System: Based on your height and weight, it appears that you are slightly overweight. However, it's important to remember that body weight is not the only indicator of health. Your body composition and overall health are more important than your weight.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\n",
      "AI: \n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n",
      "Human: what was the first question i asked?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "AI:\n",
      "\n",
      "System: You asked what the best diet for you is.\n"
     ]
    }
   ],
   "source": [
    "rsp = conversation({\"question\": \"what was the first question i asked?\"})\n",
    "print(rsp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d248ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef82de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb2f083b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79d7ae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'orange']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "chain.invoke({\"text\": \"colors\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06159587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ff5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa531a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7c8a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" You are an online Nutrition Coach.\\n\\nYour job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.\\n\\nYou are not a doctor and you do not give medical advice\\n\\nHere is some general info about the client which is the name, height, and weight: {'name': 'John', 'height': 70, 'weight': 200}\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\" You are an online Nutrition Coach.\n",
    "\n",
    "Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.\n",
    "\n",
    "You are not a doctor and you do not give medical advice\n",
    "\n",
    "Here is some general info about the client which is the name, height, and weight: {user_profile}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = PromptTemplate(input_variables=['user_profile'],\n",
    "                           template=prompt_template)\n",
    "\n",
    "user_profile = {'name': 'John', 'height': 70, 'weight': 200}\n",
    "qa_prompt_content = qa_prompt.format(**{\"user_profile\": user_profile})\n",
    "qa_prompt_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a50cb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "qa_prompt_content = qa_prompt.format(**{\"user_profile\": user_profile})\n",
    "llm = OpenAI(openai_api_key=OPENAPI_KEY, temperature=0.4)\n",
    "chain = LLMChain(llm=llm, prompt=qa_prompt, memory=memory)\n",
    "#user_profile = str({'name': 'Jane', 'height': 70, 'weight': 200})\n",
    "#$chain.run(user_profile=user_profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc79a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNo, I do not know how tall you are. However, I can help you figure out your ideal weight range based on your height. Can you provide me with your height so I can calculate your ideal weight range?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"do you know how tall i am?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a8933a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: {'name': 'Jane', 'height': 70, 'weight': 200}\\nAI: \\n\\nHi Jane! It's great to meet you. Based on your height and weight, it looks like you could benefit from making some changes to your diet and lifestyle. I'm here to help you reach your goals and improve your overall health. Let's start by talking about your current eating habits. What do you typically eat in a day?\\nHuman: do you know how tall i am?\\nAI: \\nNo, I do not know how tall you are. However, I can help you figure out your ideal weight range based on your height. Can you provide me with your height so I can calculate your ideal weight range?\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "298dc0e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects ['user_profile', 'history'], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m ConversationChain\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(openai_api_key\u001b[39m=\u001b[39mOPENAPI_KEY, temperature\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m convo \u001b[39m=\u001b[39m ConversationChain(llm \u001b[39m=\u001b[39;49m OpenAI(temperature\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m),  prompt\u001b[39m=\u001b[39;49mqa_prompt)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m convo\u001b[39m.\u001b[39mrun(user_profile\u001b[39m=\u001b[39muser_profile)\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects ['user_profile', 'history'], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\" You are an online Nutrition Coach.\n",
    "\n",
    "Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.\n",
    "\n",
    "You are not a doctor and you do not give medical advice\n",
    "\n",
    "Here is some general info about the client which is the name, height, and weight: {user_profile}\n",
    "\n",
    "{history}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = PromptTemplate(input_variables=['user_profile', 'history'],\n",
    "                           template=prompt_template)\n",
    "\n",
    "user_profile = {'name': 'John', 'height': 70, 'weight': 200}\n",
    "\n",
    "\n",
    "llm = OpenAI(openai_api_key=OPENAPI_KEY, temperature=0.4)\n",
    "convo = ConversationChain(llm = OpenAI(temperature=0.3),  prompt=qa_prompt)\n",
    "convo.run(user_profile=user_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70397207",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects ['user_profile', 'history', 'input'], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m PROMPT \u001b[39m=\u001b[39m PromptTemplate(input_variables\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39muser_profile\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m], template\u001b[39m=\u001b[39mtemplate)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(temperature\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m conversation \u001b[39m=\u001b[39m ConversationChain(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     prompt\u001b[39m=\u001b[39;49mPROMPT,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     llm\u001b[39m=\u001b[39;49mllm,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     memory\u001b[39m=\u001b[39;49mConversationBufferMemory(ai_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAI Assistant\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.70.25.107/home/jjanzen/localfiles/bbdt_backend/jupyter_notebook/chatGBT/langchain_crash_cource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects ['user_profile', 'history', 'input'], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)"
     ]
    }
   ],
   "source": [
    "user_profile = str({'name': 'John', 'height': 70, 'weight': 200})\n",
    "# Now we can override it and set it to \"AI Assistant\"\n",
    "template = \"\"\"You are an online Nutrition Coach.\n",
    "\n",
    "Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.\n",
    "\n",
    "You are not a doctor and you do not give medical advice\n",
    "\n",
    "Here is some general info about the client which is the name, height, and weight: {user_profile}\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI Assistant:\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"user_profile\", \"history\", \"input\"], template=template)\n",
    "llm = OpenAI(temperature=0.4)\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory(ai_prefix=\"AI Assistant\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c744a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an online Nutrition Coach.\n",
      "\n",
      "Your job is to answer the clients questions using your knowledge of nutrition and your experience as a coach.\n",
      "\n",
      "You are not a doctor and you do not give medical advice\n",
      "\n",
      "Here is some general info about the client which is the name, height, and weight: \n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI Assistant:  Hi there! How can I help you?\n",
      "Human: What should I eat?\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" That's a great question! Eating a balanced diet is the key to good nutrition. A balanced diet should include a variety of fruits, vegetables, whole grains, lean proteins, and healthy fats. It's also important to stay hydrated by drinking plenty of water. Are there any specific foods or nutrients you would like to focus on?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What should I eat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef146c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58261416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa6d70a-871d-4a4c-98a2-8e21cafd0881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************** 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\n",
      "\n",
      "\n",
      "Becoming a competitive natural bodybuilder is a very difficult task. It requires a great deal of dedication, hard work, and discipline. You must have a strict diet and exercise regimen, and you must be willing to push yourself to the limit. You must also have a strong mental focus and determination to stay on track. It is also important to have a good support system in place to help you stay motivated and on track.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = OpenAI(openai_api_key=OPENAPI_KEY, temperature=0.4)\n",
    "name = llm(\"how hard is it to become a competitve natural bodybuilder\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24dca200-a37f-40ce-8f49-5ac0fd5547d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I get good at playing natural bodybuilding competitvely'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"sport\"],\n",
    "    template = \"How do I get good at playing {sport} competitvely\"\n",
    ")\n",
    "prompt_template_name.format(sport=\"natural bodybuilding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44a5eff8-8c43-4ba8-a551-52b267e1c9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\n1. Learn the fundamentals: The most important part of becoming a competitive lacrosse player is mastering the fundamentals. This includes learning how to pass, catch, cradle, shoot, and defend.\\n\\n2. Practice: The only way to get better at lacrosse is to practice. Spend time working on individual skills and drills, and join a team or a league to get more practice and game experience.\\n\\n3. Watch the game: Watch professional and college lacrosse games to learn from the best and to pick up tips and strategies.\\n\\n4. Condition: Lacrosse is a physically demanding sport, so make sure to stay in shape with a good conditioning program.\\n\\n5. Study: Read books and articles on lacrosse and watch instructional videos to learn more about the game.\\n\\n6. Get the right equipment: Invest in quality lacrosse equipment that fits properly and is suited to your level of play.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"La Crosse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00c0b4d0-34c3-415c-9736-8ebeb589b651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.4)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"sport\"],\n",
    "    template = \"What skill is most important to develop to be competitive at {sport}\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = [\"skill\"],\n",
    "    template = \"How do I best develop this {skill}.  Return it as a comma separated list\"\n",
    ")\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3b70888-ca2a-4255-954f-837af6296e02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "The most important skill to develop to be competitive at wrestling is mental toughness. Mental toughness is the ability to stay focused and motivated in high-pressure situations. It involves having the mental fortitude to push through pain and fatigue and remain confident in your abilities. Mental toughness is essential for success in wrestling, as it can give you the edge you need to outlast your opponents and come out on top.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Mental toughness, focus, motivation, fortitude, pain tolerance, fatigue resistance, confidence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Mental toughness, focus, motivation, fortitude, pain tolerance, fatigue resistance, confidence.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, items_chain], verbose=True)\n",
    "response = chain.run('wrestling')\n",
    "print(response)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fa9139-a131-4578-b1b3-31e4e63f6f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.4)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"sport\"],\n",
    "    template = \"What skill is most important to develop to be competitive at {sport}\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"skill\")\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = [\"skill\"],\n",
    "    template = \"How do I best develop this {skill}.  Return it as a comma separated list\"\n",
    ")\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"skill_list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf83055d-857d-43f7-8f85-a01d73a9ce50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sport': 'wrestling',\n",
       " 'skill': '\\n\\nThe most important skill to develop to be competitive at wrestling is physical conditioning. Wrestling is an extremely demanding sport that requires athletes to have a high level of physical strength, endurance, and agility. Wrestlers must be able to endure long practices and intense matches. Additionally, wrestlers must be able to quickly react to their opponents’ movements and have the strength and agility to execute their own moves.',\n",
       " 'skill_list': '\\n\\nPhysical conditioning, strength, endurance, agility, quick reaction, strength, agility.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain, items_chain],\n",
    "    input_variables= ['sport'],\n",
    "    output_variables=['skill', 'skill_list']\n",
    ")\n",
    "chain( {'sport':'wrestling'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057c5ae-0c72-44f7-ba38-5fa2412223fb",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6b8b02-4c78-4934-9d8c-565abd046414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'500 x 3 = 1500'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "tools = load_tools([ 'llm-math'], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "agent.run(\"what if 500 times 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0108eecc-dc2a-4f40-a439-fa3d84539052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who leads the MLB in batting average and how many hits they need to set the record\n",
      "Action: Search\n",
      "Action Input: \"MLB batting average leader\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. Luis Arraez. L. ArraezMIA .357 ; 2. Freddie Freeman. F. FreemanLAD .333 ; 3. Ronald Acuna Jr. R. Acuna Jr.ATL .331 ; 4. Yandy Diaz. Y. DiazTB .325.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out how many hits the leader needs to set the record\n",
      "Action: Search\n",
      "Action Input: \"MLB hits record\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mJulio Rodríguez sets MLB record with 17 hits in four games.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Luis Arraez leads the MLB in batting average with a .357 average and needs 17 more hits to set the MLB record.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Luis Arraez leads the MLB in batting average with a .357 average and needs 17 more hits to set the MLB record.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = load_tools(['serpapi', 'llm-math'], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    "    , verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"who leads the major league in batting average right now and how many hits does he need to set the MLB record?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c762e-57c3-423a-bd91-ed451c545aa1",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5147d186-fafb-4518-8947-778198867b67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe most important skill to develop to be competitive at sprinting is speed. This means that you must be able to move quickly and with power, and you must be able to maintain your speed throughout the race. You must also be able to use proper technique to maximize your efficiency and speed. Additionally, you must have the ability to maintain your form and stay relaxed, as well as have a strong mental game to stay focused and motivated. Finally, you must have the ability to stay healthy and injury-free to ensure that you can consistently perform at your best.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "name = chain.run(\"sprinting\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e31b90f-97a8-4fa8-93c8-979a5b2733ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc14d24-e0e9-46bb-adb5-4ffc06e2cfda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The most important skill to develop to be competitive at sprinting is speed. Speed is the most important factor in sprinting, and having good speed is essential for achieving success in this sport. Other important skills include strength, agility, coordination, and technique. Developing these skills will help you become a better sprinter and give you an edge over your competitors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='sprinting', additional_kwargs={}, example=False), AIMessage(content='\\n\\nThe most important skill to develop to be competitive at sprinting is speed. Speed is the most important factor in sprinting, and having good speed is essential for achieving success in this sport. Other important skills include strength, agility, coordination, and technique. Developing these skills will help you become a better sprinter and give you an edge over your competitors.', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory \n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.run(\"sprinting\")\n",
    "print(name)\n",
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c0301c4-cbe8-4679-9c55-3cf2b584fa69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm = OpenAI(temperature=0.3))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ea2d8b-b53a-42ae-9517-237203ee02a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" That depends on the type of race. For example, if it's a running race, then the fastest animal would likely be a cheetah. If it's a swimming race, then the fastest animal would likely be a dolphin.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what animal wins the race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce86aac4-7f0a-43dc-afc4-aaadbfed1dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Grass is typically green in color. However, it can also be other colors such as yellow, brown, or even purple depending on the type of grass and the environment it is growing in.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what color is grass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "909087d8-f4f2-4e64-97b8-e93e3c425298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: who wins the race\n",
      "AI:  I'm sorry, I don't know the answer to that.\n",
      "Human: what animal wins the race\n",
      "AI:  That depends on the type of race. For example, if it's a running race, then the fastest animal would likely be a cheetah. If it's a swimming race, then the fastest animal would likely be a dolphin.\n",
      "Human: what color is grass\n",
      "AI:  Grass is typically green in color. However, it can also be other colors such as yellow, brown, or even purple depending on the type of grass and the environment it is growing in.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5489d5e4-637d-463b-a1a2-8937cfd897a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The cheetah would win the race between a turtle and a cheetah. Cheetahs are the fastest land animals, reaching speeds of up to 75 mph. Turtles, on the other hand, typically move at a much slower pace, usually between 0.17 and 0.31 mph.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "convo = ConversationChain(llm = OpenAI(temperature=0.3), memory=memory)\n",
    "\n",
    "convo.run(\"what animal wins the race between turtle and cheetah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abc65209-32d9-4ffb-9b56-a183e05cbf38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: what animal wins the race between turtle and cheetah\n",
      "AI:  The cheetah would win the race between a turtle and a cheetah. Cheetahs are the fastest land animals, reaching speeds of up to 75 mph. Turtles, on the other hand, typically move at a much slower pace, usually between 0.17 and 0.31 mph.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94427784-4da7-4657-8ea0-6e3563267389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Grass is typically green in color. This is due to the presence of chlorophyll, which is a pigment that helps plants absorb energy from the sun.\n"
     ]
    }
   ],
   "source": [
    "print(convo.run(\"what color is grass\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "358361d5-2844-4a22-8c5e-69e8de663abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: what color is grass\n",
      "AI:  Grass is typically green in color. This is due to the presence of chlorophyll, which is a pigment that helps plants absorb energy from the sun.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "977bdd34-de4e-4e18-9ba4-58a7adef3c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I don't know what animal you are referring to. Could you provide more context?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what animal was it again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c96f79-f30c-4a1d-aed0-f7e880f37510",
   "metadata": {},
   "source": [
    "# Nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17906cab-824e-4d76-a214-1e969e4c484e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"La Crosse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26993c-bd3e-4339-933f-4c900a3f5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "tools = load_tools([ 'llm-math', 'serpapi'], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    "    , verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"who leads the major league in batting average right now and how many hits does he need to set the MLB record?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ff78783-9fb4-4456-ae0b-f73ab7b2f715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. 'tools' (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prompt_template_name \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat skill is most important to develop to be competitive at \u001b[39;49m\u001b[38;5;132;43;01m{sport}\u001b[39;49;00m\u001b[38;5;124;43m You have access to the following tools: \u001b[39;49m\u001b[38;5;132;43;01m{tools}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m name_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt_template_name, output_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskill\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m prompt_template_items \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m      9\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskill\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m     template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow do I best develop this \u001b[39m\u001b[38;5;132;01m{skill}\u001b[39;00m\u001b[38;5;124m.  Return it as a comma separated list\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. 'tools' (type=value_error)"
     ]
    }
   ],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = [\"sport\"],\n",
    "    template = \"What skill is most important to develop to be competitive at {sport} You have access to the following tools: {tools}\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"skill\")\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = [\"skill\"],\n",
    "    template = \"How do I best develop this {skill}.  Return it as a comma separated list\"\n",
    ")\n",
    "items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"skill_list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cdc5034-1c2e-4e3b-8f1a-86b9ae6c05b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sport': 'wrestling',\n",
       " 'skill': '\\n\\nThe most important skill to develop to be competitive at wrestling is physical conditioning. Wrestling requires a high level of fitness, strength, and endurance, and an athlete must have the ability to push their body to its limits. Additionally, developing technical skills such as takedowns, throws, and pinning combinations is essential. Finally, having a strong mental game and the ability to focus and stay calm under pressure is key for success in wrestling.',\n",
       " 'skill_list': '\\n\\nPhysical conditioning, technical skills, strong mental game, ability to focus and stay calm under pressure.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain, items_chain],\n",
    "    input_variables= ['sport'],\n",
    "    output_variables=['skill', 'skill_list']\n",
    ")\n",
    "chain( {'sport':'wrestling'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e59e7-c480-4f35-bd76-7b45aa1902cb",
   "metadata": {},
   "source": [
    "# Custom Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ebd1769c-9c4f-4d32-999a-925cce933b74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llm-math', 'serpapi']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain, LLMMathChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re\n",
    "\n",
    "# Define which tools the agent can use to answer user queries\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]\n",
    "\n",
    "[ 'llm-math', 'serpapi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4f2f72d-701c-4653-8430-0f7d1827a745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e19dacda-9b3e-4cb2-a1f3-7e82995202b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "453aea81-de87-4425-9ab3-4527b0348c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3dd3e09a-6916-481a-ba0c-88a37fd8d9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87056a10-be61-4a3a-9f37-a0ec5cc9ce50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "166b2b63-6664-4bb9-b6d4-3a3c2778d9ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5da48c77-f938-4c9c-a7f0-fac362bbe4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6d2f527-ad50-4098-a412-02791a142a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the population of Canada in 2023\n",
      "Action: Search\n",
      "Action Input: Population of Canada in 2023\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m38,781,291\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Arrr, Canada be havin' 38,781,291 people livin' there in 2023!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Arrr, Canada be havin' 38,781,291 people livin' there in 2023!\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71942ea-b003-4c32-9d99-27d829044133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
