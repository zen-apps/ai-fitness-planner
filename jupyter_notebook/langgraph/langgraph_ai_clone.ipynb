{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import (\n",
    "    JsonOutputParser,\n",
    ")\n",
    "from langchain.tools import (\n",
    "    Tool,\n",
    ")\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "from typing import TypedDict, Optional, List, Tuple, Literal, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%sh \n",
    "\n",
    "#pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv(\"../config/dev.env\")\n",
    "OPENAPI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(api_key=OPENAPI_KEY, model=\"gpt-4o\", temperature=0.0)\n",
    "#llm.invoke(\"heelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathQuestion(answer_1=True, answer_2=False, answer_3=False, answer_4=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "question = \"there were 10 apples in a basket. 5 apples were taken out. How many apples are left in the basket?\"\n",
    "possible_answers = [\"5\", \"10\", \"15\", \"0\"]\n",
    "\n",
    "word_problem_template = \"\"\"You are a teacher developing exam questions for students. \n",
    "You have this question {question} that you want to ask your students and these four possible answers {possible_answers}.\n",
    "You need to validate that each possible answer and return if the answer is correct or incorrect.\"\"\"\n",
    "\n",
    "math_assistant_prompt = PromptTemplate(input_variables=[\"question\"],\n",
    "                                       template=word_problem_template\n",
    "                                       )\n",
    "llm_math = LLMMathChain.from_llm(llm=llm)\n",
    "\n",
    "word_problem_tool = Tool(name=\"MathReasoningTool\",\n",
    "                                       func=llm_math.run,\n",
    "                                       description=\"A tool that helps you solve logic-based questions\",\n",
    "                                    )\n",
    "tools = [word_problem_tool]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "class MathQuestion(BaseModel):\n",
    "   answer_1: bool = Field(description=\"Is the first answer correct?\")\n",
    "   answer_2: bool = Field(description=\"Is the second answer correct?\")\n",
    "   answer_3: bool = Field(description=\"Is the third answer correct?\")\n",
    "   answer_4: bool = Field(description=\"Is the fourth answer correct?\")\n",
    "\n",
    "\n",
    "prompt = word_problem_template.format(question=question, possible_answers=possible_answers)\n",
    "#rsp = llm_with_tools.invoke([prompt])\n",
    "rsp = llm_with_tools.with_structured_output(MathQuestion).invoke([prompt])\n",
    "rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: \n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from typing import List, Dict, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class MathProblemSolver:\n",
    "    def __init__(self, model_name: str = \"gpt-4\", temperature: float = 0.0):\n",
    "        \"\"\"\n",
    "        Initialize the Math Problem Solver with necessary components\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): The OpenAI model to use (default: \"gpt-4\")\n",
    "            temperature (float): The temperature setting for the model (default: 0.0)\n",
    "        \"\"\"\n",
    "        # Get API key from environment variables\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "        # Initialize the LLM (fixed model name from \"gpt-4o\" to \"gpt-4\")\n",
    "        self.llm = ChatOpenAI(\n",
    "            api_key=self.api_key,\n",
    "            model_name=model_name,\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        # Create the prompt template (fixed indentation)\n",
    "        self.word_problem_template = \"\"\"You are a reasoning agent tasked with solving \n",
    "the user's logic-based questions. Logically arrive at the solution, and be \n",
    "factual. In your answers, clearly detail the steps involved and give the \n",
    "final answer. Provide the response in bullet points.\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        self.math_assistant_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\"],\n",
    "            template=self.word_problem_template\n",
    "        )\n",
    "        \n",
    "        # Initialize the math chain\n",
    "        self.llm_math = LLMMathChain.from_llm(llm=self.llm)\n",
    "        \n",
    "        # Create the reasoning tool\n",
    "        self.word_problem_tool = Tool(\n",
    "            name=\"Reasoning Tool\",\n",
    "            func=self.llm_math.run,\n",
    "            description=\"A tool that helps you solve logic-based questions\"\n",
    "        )\n",
    "        \n",
    "        # Bind tools to the LLM\n",
    "        self.llm_with_tools = self.llm.bind_tools([self.word_problem_tool])\n",
    "    \n",
    "    def solve_problem(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Solve a given math problem\n",
    "        \n",
    "        Args:\n",
    "            question (str): The math problem to solve\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, Any]: Response containing the solution and metadata\n",
    "        \"\"\"\n",
    "        if not isinstance(question, str) or not question.strip():\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"question\": question,\n",
    "                \"solution\": None,\n",
    "                \"error\": \"Invalid question format or empty question\"\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            # Format the prompt\n",
    "            prompt = self.math_assistant_prompt.format(question=question)\n",
    "            \n",
    "            # Get the response\n",
    "            response = self.llm_with_tools.invoke(prompt)\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"question\": question,\n",
    "                \"solution\": response,\n",
    "                \"error\": None\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"question\": question,\n",
    "                \"solution\": None,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def solve_multiple_problems(self, questions: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Solve multiple math problems\n",
    "        \n",
    "        Args:\n",
    "            questions (List[str]): List of math problems to solve\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: List of responses for each problem\n",
    "        \"\"\"\n",
    "        if not isinstance(questions, list):\n",
    "            return [{\n",
    "                \"status\": \"error\",\n",
    "                \"question\": None,\n",
    "                \"solution\": None,\n",
    "                \"error\": \"Input must be a list of questions\"\n",
    "            }]\n",
    "            \n",
    "        return [self.solve_problem(q) for q in questions]\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate the usage of MathProblemSolver\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the solver\n",
    "        solver = MathProblemSolver()\n",
    "        \n",
    "        # Single problem\n",
    "        question = \"There were 10 apples in a basket. 5 apples were taken out. How many apples are left in the basket?\"\n",
    "        result = solver.solve_problem(question)\n",
    "        print(\"\\nSingle Problem Result:\")\n",
    "        print(result)\n",
    "        \n",
    "        # Multiple problems\n",
    "        questions = [\n",
    "            \"There were 10 apples in a basket. 5 apples were taken out. How many apples are left in the basket?\",\n",
    "            \"If John has 15 marbles and gives 3 to Mary, how many does he have left?\"\n",
    "        ]\n",
    "        results = solver.solve_multiple_problems(questions)\n",
    "        print(\"\\nMultiple Problems Results:\")\n",
    "        for result in results:\n",
    "            print(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    init_input: Optional[str]\n",
    "    fruit: Optional[str]\n",
    "    final_result: Optional[str]\n",
    "    ai_confirmation: Optional[bool]\n",
    "    revision_count: Optional[int]\n",
    "    init_input_length: Optional[int]\n",
    "    output_length: Optional[int]\n",
    "\n",
    "def input_fruit(state: GraphState) -> GraphState:\n",
    "    print(\"Node: input_fruit\")\n",
    "    init_input = state.get(\"init_input\", \"\").strip().lower()\n",
    "    state[\"fruit\"] = init_input\n",
    "    return state\n",
    "\n",
    "def review_fruit(state: GraphState) -> GraphState:\n",
    "    print(\"--------------------\")\n",
    "    print(\"Node: review_fruit\")\n",
    "    print(f\"Review your selection: {state['fruit']}, is this correct?\")\n",
    "\n",
    "    class ValidFruit(BaseModel):\n",
    "        fruit: str = Field(..., title=\"Fruit\", description=\"The fruit you selected\")\n",
    "        valid_fruit: bool = Field(..., title=\"Valid Fruit\", description=\"Is the fruit valid?\")\n",
    "\n",
    "    message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": f\"Review your selection: {state['fruit']}, is this correct?\"}\n",
    "    ])\n",
    "    response = llm.with_structured_output(ValidFruit).invoke([message])\n",
    "    valid_fruit = response.valid_fruit\n",
    "\n",
    "    if valid_fruit:\n",
    "        state[\"ai_confirmation\"] = True\n",
    "    else:\n",
    "        state[\"ai_confirmation\"] = False\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_fruit(state: GraphState) -> GraphState:\n",
    "    print(\"--------------------\")\n",
    "    print(\"Node: rename_fruit\")\n",
    "    print(f\"Rename the fruit: {state['fruit']} to an actual fruit\")\n",
    "\n",
    "    # appending old attempts to rename the fruit that did not pass ai_confirmation\n",
    "    if state.get(\"revision_count\", 0) > 0:\n",
    "        previous_attempt = AIMessage(content=f\"Rename the fruit: {state['fruit']} to an actual fruit\")\n",
    "        correction_feedback = AIMessage(content=f\"Confirmation if correct{state['ai_confirmation']}\")\n",
    "    else:\n",
    "        print(\"No previous attempts to rename the fruit\")\n",
    "\n",
    "    class FruitRename(BaseModel):\n",
    "        fruit: str = Field(..., title=\"Fruit\", description=\"The fruit you selected\")\n",
    "\n",
    "    system_message = SystemMessage(content=f\"\"\"Rename the fruit: {state['fruit']} to an actual fruit.  Use aggressive renaming and trying differernt letter in the\n",
    "                                   alphabet to make a valid fruit.\n",
    "                                   RULES:\n",
    "                                   1. You must use at least the first letter of the fruit you selected.\n",
    "                                   2. The output must be a valid fruit.\n",
    "                                   3. Do not use the same answer as before.\"\"\")\n",
    "    if state.get(\"revision_count\", 0) > 0:\n",
    "        messages = [previous_attempt, correction_feedback, system_message]\n",
    "    else:\n",
    "        messages = [system_message]\n",
    "    response = llm.with_structured_output(FruitRename).invoke(messages)\n",
    "    print('fixing fruit response:', response)\n",
    "    state[\"fruit\"] = response.fruit\n",
    "    revision_count = state.get(\"revision_count\", 0)\n",
    "    state[\"revision_count\"] = revision_count + 1\n",
    "\n",
    "    return state\n",
    "\n",
    "def review_decision(state: GraphState) -> Tuple[Literal[\"summarize_output\", \"rename_fruit\"]]:\n",
    "    print(\"--------------------\")\n",
    "    print(\"Function Edge: review_decision\")\n",
    "    print(f\"Function Edge Contine: state: {state}\")\n",
    "\n",
    "    if state.get(\"ai_confirmation\") == True:\n",
    "        print(\"Function Edge: reveiw_decision -> summarize_output\")\n",
    "        return \"summarize_output\"\n",
    "    elif state.get(\"ai_confirmation\") == False:\n",
    "        print(\"Function Edge Continue: to_error\")\n",
    "        return \"rename_fruit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.add_node(\"summarize_output\", action=summarize_output)\n",
    "def summarize_output(state: GraphState) -> Dict[str, str]:\n",
    "    print(\"--------------------\")\n",
    "    print(\"Node: summarize_output\")\n",
    "    \n",
    "    if state.get(\"ai_confirmation\") and (state.get(\"init_input\") != state.get(\"fruit\")):\n",
    "        return {\"final_result\": f\"you entered {state['init_input']} and the AI corrected it to {state['fruit']}\"}\n",
    "    elif state.get(\"ai_confirmation\") and (state.get(\"init_input\") == state.get(\"fruit\")):\n",
    "        return {\"final_result\": f\"you entered {state['init_input']} and the AI confirmed it\"}\n",
    "    elif state.get(\"ai_confirmation\") == False:\n",
    "        return {\"final_result\": f\"you entered {state['init_input']} and the AI could not correct it\"}\n",
    "\n",
    "MAX_REVISIONS = 3\n",
    "def extract_or_end(state: GraphState) -> Tuple[Literal[\"review_fruit\", \"summarize_output\"]]:\n",
    "    if state.get(\"revision_count\", 0) >= MAX_REVISIONS:\n",
    "        return \"summarize_output\"\n",
    "    else:\n",
    "        return \"review_fruit\"\n",
    "    \n",
    "def word_problem_tool(state: GraphState) -> Dict[str, str]:\n",
    "    print(\"--------------------\")\n",
    "    print(\"Node: math_tool_llm\")\n",
    "\n",
    "    problem_chain = LLMMathChain.from_llm(llm=llm)\n",
    "    math_tool = Tool.from_function(\n",
    "        name=\"Calculator\",\n",
    "        func=problem_chain.run,\n",
    "        description=\"Useful for when you need to answer questions about math. Only use this tool with numbers. This tool is only for math questions and nothing else. Only input math expressions.\",\n",
    "    )\n",
    "\n",
    "    word_problem_template = \"\"\"You are a reasoning agent tasked with solving \n",
    "    the user's logic-based questions. Logically arrive at the solution, and be \n",
    "    factual. In your answers, clearly detail the steps involved and give the \n",
    "    final answer. Provide the response in bullet points. \n",
    "    Question: {question} \n",
    "    Answer:\"\"\"\n",
    "\n",
    "    math_assistant_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"], template=word_problem_template\n",
    "    )\n",
    "\n",
    "    word_problem_chain = LLMChain(llm=llm, prompt=math_assistant_prompt)\n",
    "    word_problem_tool = Tool.from_function(\n",
    "        name=\"Reasoning Tool\",\n",
    "        func=word_problem_chain.run,\n",
    "        description=\"Useful for when you need to answer logic-based/reasoning questions.\",\n",
    "    )\n",
    "\n",
    "    init_input = state.get(\"init_input\", \"\").strip().lower()\n",
    "    state[\"init_input\"] = init_input\n",
    "    len_input = len(init_input)\n",
    "    \n",
    "    # Use Calculator tool\n",
    "    question = f\"What is {len_input} + 1?\"\n",
    "    result = problem_chain.run(question)\n",
    "    \n",
    "    # Update state with results\n",
    "    state[\"init_input\"] = str(result)\n",
    "    state[\"init_input_length\"] = len_input\n",
    "    state[\"output_length\"] = int(result)\n",
    "    \n",
    "    return {\"init_input\": state[\"init_input\"], \"init_input_length\": len_input, \"output_length\": int(result)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: input_fruit\n",
      "--------------------\n",
      "Node: review_fruit\n",
      "Review your selection: ap, is this correct?\n",
      "--------------------\n",
      "Function Edge: review_decision\n",
      "Function Edge Contine: state: {'init_input': 'ap', 'fruit': 'ap', 'ai_confirmation': False}\n",
      "Function Edge Continue: to_error\n",
      "--------------------\n",
      "Node: rename_fruit\n",
      "Rename the fruit: ap to an actual fruit\n",
      "No previous attempts to rename the fruit\n",
      "fixing fruit response: fruit='apple'\n",
      "--------------------\n",
      "Node: review_fruit\n",
      "Review your selection: apple, is this correct?\n",
      "--------------------\n",
      "Function Edge: review_decision\n",
      "Function Edge Contine: state: {'init_input': 'ap', 'fruit': 'apple', 'ai_confirmation': True, 'revision_count': 1}\n",
      "Function Edge: reveiw_decision -> summarize_output\n",
      "--------------------\n",
      "Node: summarize_output\n",
      "--------------------\n",
      "Node: math_tool_llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76006/2652618489.py:55: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = problem_chain.run(question)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Answer: 3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m app \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Test with a valid fruit\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1586\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1586\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1588\u001b[0m     config,\n\u001b[1;32m   1589\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   1590\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1591\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   1592\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   1593\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1595\u001b[0m ):\n\u001b[1;32m   1596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1597\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1315\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1310\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1311\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1312\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1313\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1314\u001b[0m     ):\n\u001b[0;32m-> 1315\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1316\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1317\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1318\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1319\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1320\u001b[0m         ):\n\u001b[1;32m   1321\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/localfiles/.venv/lib/python3.9/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[27], line 60\u001b[0m, in \u001b[0;36mword_problem_tool\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     58\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_input\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(result)\n\u001b[1;32m     59\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_input_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m len_input\n\u001b[0;32m---> 60\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_input\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_input_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: len_input, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(result)}\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Answer: 3'"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.set_entry_point(\"input_fruit\")\n",
    "workflow.add_node(\"input_fruit\", action=input_fruit)\n",
    "workflow.add_node(\"review_fruit\", action=review_fruit)\n",
    "workflow.add_node(\"rename_fruit\", action=rename_fruit)\n",
    "workflow.add_node(\"summarize_output\", action=summarize_output)\n",
    "workflow.add_node(\"math_tool_llm\", action=word_problem_tool)\n",
    "\n",
    "workflow.add_edge(\"input_fruit\", \"review_fruit\")\n",
    "workflow.add_edge(\"summarize_output\", \"math_tool_llm\")\n",
    "workflow.add_edge(\"math_tool_llm\", END)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"review_fruit\",\n",
    "    path=review_decision,\n",
    "    path_map={\n",
    "        \"summarize_output\": \"summarize_output\",\n",
    "        \"rename_fruit\": \"rename_fruit\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"rename_fruit\",\n",
    "    path=extract_or_end,\n",
    "    path_map={\n",
    "        \"review_fruit\": \"review_fruit\",\n",
    "        \"summarize_output\": \"summarize_output\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# Test with a valid fruit\n",
    "result = app.invoke({\"init_input\": \"ap\"})\n",
    "print(\"-------\")\n",
    "for k, v in result.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
